{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import TypedDict, Annotated, List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from dotenv import load_dotenv\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain.agents.output_parsers import OpenAIFunctionsAgentOutputParser\n",
    "from langchain_core.messages import AnyMessage, SystemMessage, HumanMessage\n",
    "from langchain.agents import AgentExecutor, create_openai_functions_agent\n",
    "from langchain_core.pydantic_v1 import BaseModel\n",
    "\n",
    "from langgraph.checkpoint.sqlite import SqliteSaver\n",
    "from langgraph.graph import StateGraph, END\n",
    "\n",
    "from langchain import hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tavily import TavilyClient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Markdown, display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LANGUAGE = 'english'\n",
    "TAVILY_MAX_RESULTS = 5\n",
    "MAX_QUERIES = 5\n",
    "TAVILY_API_KEY = os.environ[\"TAVILY_API_KEY\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tavily = TavilyClient(api_key=TAVILY_API_KEY)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AgentState(TypedDict):\n",
    "    task: str\n",
    "    plan: str\n",
    "    draft: str\n",
    "    translation: str\n",
    "    target_language: str\n",
    "    queries: List[str]\n",
    "    critique: str\n",
    "    content: List[str]\n",
    "    revision_number: int\n",
    "    max_revisions: int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "memory = SqliteSaver.from_conn_string(\":memory:\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ChatOpenAI(model='gpt-4o-mini', temperature=0, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "translation_prompt = hub.pull(\"haha918301/translator\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "translation_prompt.template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PLAN_PROMPT = \"\"\"You are an expert writer specialised on unbiased information veryfication in the context of dezinformation, conspiracy theories and propaganda. \\\n",
    "You are tasked with writing a high level outline of an expository article. \\\n",
    "Write such an outline for the user provided topic. Give an outline of the expository article along with any relevant notes \\\n",
    "or instructions for the sections.\"\"\"\n",
    "\n",
    "RESEARCH_PLAN_PROMPT = \"\"\"You are a researcher charged with providing information that can \\\n",
    "be used when writing the following expository article. Generate a list of search queries that will gather \\\n",
    "any relevant information. Only generate {max_queries} queries max.\"\"\".format(max_queries=MAX_QUERIES)\n",
    "\n",
    "TRANSLATION_PROMPT = translation_prompt\n",
    "\n",
    "DRAFT_PROMPT = \"\"\"You are an expository article assistant tasked with writing excellent 5-paragraph expository article.\\\n",
    "Generate the best unbiased expository article possible for the user's request and the initial outline. \\\n",
    "If the user provides critique, respond with a revised version of your previous attempts. \\\n",
    "Utilize only the information below, don't add any new information, make up or gues anything, or change the topic. : \n",
    "\n",
    "------\n",
    "\n",
    "{content}\"\"\"\n",
    "\n",
    "REFLECTION_PROMPT = \"\"\"You are a teacher grading an essay submission. \\\n",
    "Generate critique and recommendations for the user's submission. \\\n",
    "Provide detailed recommendations, including requests for length, depth, style, etc.\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "RESEARCH_CRITIQUE_PROMPT = \"\"\"You are a researcher charged with providing information that can \\\n",
    "be used when making any requested revisions (as outlined below). \\\n",
    "Generate a list of search queries that will gather any relevant information. Only generate 3 queries max.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_plan(state):\n",
    "\n",
    "    messages = [\n",
    "        SystemMessage(content=PLAN_PROMPT), \n",
    "        HumanMessage(content=state['task'])\n",
    "    ]\n",
    "    response = model.invoke(messages)\n",
    "    plan = response.content\n",
    "    \n",
    "    return plan\n",
    "\n",
    "def plan_node(state: AgentState):\n",
    "    \n",
    "    plan = get_plan(state)\n",
    "    \n",
    "    return {'plan': plan}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_queries(state: AgentState):\n",
    "    \n",
    "    class Queries(BaseModel):\n",
    "        queries: List[str]\n",
    "        \n",
    "    messages = [\n",
    "        SystemMessage(content=RESEARCH_PLAN_PROMPT), \n",
    "        HumanMessage(content=state['task'])\n",
    "    ]\n",
    "    queries = model.with_structured_output(Queries).invoke(messages)\n",
    "    queries = queries.queries\n",
    "\n",
    "    return queries\n",
    "\n",
    "def get_content(state, queries):\n",
    "\n",
    "    content = state['content'] or set()\n",
    "    for q in queries:\n",
    "        response = tavily.search(query=q, max_results=TAVILY_MAX_RESULTS)\n",
    "        for r in response['results']:\n",
    "            content.add(r['content'])\n",
    "    \n",
    "    return content\n",
    "\n",
    "def research_plan_node(state: AgentState):\n",
    "    \n",
    "    queries = get_queries(state)\n",
    "    content = get_content(state, queries)\n",
    "\n",
    "    return {\"content\": content, \"queries\": queries}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_draft(state: AgentState):\n",
    "    \n",
    "    content = \"<<<<<<>>>>>>\".join(state['content'] or [])\n",
    "    user_message = f\"{state['task']}\\n\\nHere is my plan:\\n\\n{state['plan']}\"\n",
    "    \n",
    "    draft_promp = DRAFT_PROMPT.format(content=content)\n",
    "    messages = [\n",
    "        SystemMessage(content=draft_promp),\n",
    "        HumanMessage(content=user_message)\n",
    "    ]\n",
    "    \n",
    "    response = model.invoke(messages)\n",
    "    draft = response.content\n",
    "    return draft\n",
    "\n",
    "def draft_node(state: AgentState):\n",
    "    \n",
    "    draft = get_draft(state)\n",
    "    rev_num = state.get(\"revision_number\", 1) + 1\n",
    "\n",
    "    return {\"draft\": draft, \"revision_number\": rev_num}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_translation(state: AgentState):\n",
    "    translation_promp = TRANSLATION_PROMPT.format(input_language=LANGUAGE,\n",
    "                                             output_language=state['target_language'],\n",
    "                                             text=state['draft']\n",
    "                                             )\n",
    "    messages = [\n",
    "        HumanMessage(content=translation_promp)\n",
    "    ]\n",
    "    response = model.invoke(messages)\n",
    "    translation = response.content\n",
    "    \n",
    "    return translation\n",
    "\n",
    "def translate_node(state: AgentState):\n",
    "\n",
    "    translation = get_translation(state)\n",
    "    \n",
    "    return {\"translation\": translation}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "builder = StateGraph(AgentState)\n",
    "builder.add_node(\"planner_node\", plan_node)\n",
    "builder.add_node(\"research_plan_node\", research_plan_node)\n",
    "builder.add_node(\"draft_node\", draft_node)\n",
    "builder.add_node(\"translate_node\", translate_node)\n",
    "\n",
    "\n",
    "builder.set_entry_point(\"planner_node\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "builder.add_edge(\"planner_node\", \"research_plan_node\")\n",
    "builder.add_edge(\"research_plan_node\", \"draft_node\")\n",
    "builder.add_edge(\"draft_node\", \"translate_node\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = builder.compile(checkpointer=memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "\n",
    "# Image(graph.get_graph().draw_png())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thread_num = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thread_num += 1\n",
    "task = \"TODO\"\n",
    "\n",
    "thread = {\"configurable\": {\"thread_id\": str(thread_num)}}\n",
    "params = {\n",
    "    'task': task,\n",
    "    'target_language': \"czech\",\n",
    "    \"max_revisions\": 2,\n",
    "    \"revision_number\": 1,   \n",
    "}\n",
    "\n",
    "for s in graph.stream(params, thread, debug=True):\n",
    "    print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph.get_state(thread).values['queries']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph.get_state(thread).values['content']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(Markdown(graph.get_state(thread).values['draft']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(Markdown(graph.get_state(thread).values['translation']))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
